import { getAccessToken } from "./shared/auth";
import {
  convertToSiteUrl,
  getPublishMetadata,
  requestIndexing,
  getEmojiForStatus,
  getPageIndexingStatus,
} from "./shared/gsc";
import { getSitemapPages } from "./shared/sitemap";
import { Status } from "./shared/types";
import { batch } from "./shared/utils";
import { readFileSync, existsSync, mkdirSync, writeFileSync } from "fs";

const CACHE_TIMEOUT = 1000 * 60 * 60 * 24 * 14; // 14 days

const main = async () => {
  const input = process.argv[2];

  if (!input) {
    console.error("âŒ Please provide a domain or site URL as the first argument.");
    console.error("");
    process.exit(1);
  }

  const accessToken = await getAccessToken();
  const siteUrl = convertToSiteUrl(input);
  console.log(`ğŸ” Processing site: ${siteUrl}`);
  const cachePath = `.cache/${siteUrl
    .replace("http://", "http_")
    .replace("https://", "https_")
    .replace("/", "_")}.json`;

  if (!accessToken) {
    console.error("âŒ Failed to get access token, check your service account credentials.");
    console.error("");
    process.exit(1);
  }

  const [sitemaps, pages] = await getSitemapPages(accessToken, siteUrl);

  if (sitemaps.length === 0) {
    console.error("âŒ No sitemaps found, add them to Google Search Console and try again.");
    console.error("");
    process.exit(1);
  }

  console.log(`ğŸ‘‰ Found ${pages.length} URLs in ${sitemaps.length} sitemap`);

  const statusPerUrl: Record<string, { status: Status; lastCheckedAt: string }> = existsSync(cachePath)
    ? JSON.parse(readFileSync(cachePath, "utf8"))
    : {};
  const pagesPerStatus: Record<Status, string[]> = {
    [Status.SubmittedAndIndexed]: [],
    [Status.DuplicateWithoutUserSelectedCanonical]: [],
    [Status.CrawledCurrentlyNotIndexed]: [],
    [Status.DiscoveredCurrentlyNotIndexed]: [],
    [Status.PageWithRedirect]: [],
    [Status.URLIsUnknownToGoogle]: [],
    [Status.RateLimited]: [],
    [Status.Forbidden]: [],
    [Status.Error]: [],
  };

  const indexableStatuses = [
    Status.DiscoveredCurrentlyNotIndexed,
    Status.CrawledCurrentlyNotIndexed,
    Status.URLIsUnknownToGoogle,
    Status.Forbidden,
    Status.Error,
    Status.RateLimited,
  ];

  const shouldRecheck = (status: Status, lastCheckedAt: string) => {
    const shouldIndexIt = indexableStatuses.includes(status);
    const isOld = new Date(lastCheckedAt) < new Date(Date.now() - CACHE_TIMEOUT);
    return shouldIndexIt || isOld;
  };

  await batch(
    async (url) => {
      let result = statusPerUrl[url];
      if (!result || shouldRecheck(result.status, result.lastCheckedAt)) {
        const status = await getPageIndexingStatus(accessToken, siteUrl, url);
        result = { status, lastCheckedAt: new Date().toISOString() };
        statusPerUrl[url] = result;
      }

      pagesPerStatus[result.status] = pagesPerStatus[result.status] ? [...pagesPerStatus[result.status], url] : [url];
    },
    pages,
    50,
    (batchIndex, batchCount) => {
      console.log(`ğŸ“¦ Batch ${batchIndex + 1} of ${batchCount} complete`);
    }
  );

  console.log(``);
  console.log(`ğŸ‘ Done, here's the status of all ${pages.length} pages:`);
  mkdirSync(".cache", { recursive: true });
  writeFileSync(cachePath, JSON.stringify(statusPerUrl, null, 2));

  for (const status of Object.keys(pagesPerStatus)) {
    const pages = pagesPerStatus[status as Status];
    if (pages.length === 0) continue;
    console.log(`â€¢ ${getEmojiForStatus(status as Status)} ${status}: ${pages.length} pages`);
  }
  console.log("");

  const indexablePages = Object.entries(pagesPerStatus).flatMap(([status, pages]) =>
    indexableStatuses.includes(status as Status) ? pages : []
  );

  if (indexablePages.length === 0) {
    console.log(`âœ¨ There are no pages that can be indexed. Everything is already indexed!`);
  } else {
    console.log(`âœ¨ Found ${indexablePages.length} pages that can be indexed.`);
    indexablePages.forEach((url) => console.log(`â€¢ ${url}`));
  }
  console.log(``);

  for (const url of indexablePages) {
    console.log(`ğŸ“„ Processing url: ${url}`);
    const status = await getPublishMetadata(accessToken, url);
    if (status === 404) {
      await requestIndexing(accessToken, url);
      console.log("ğŸš€ Indexing requested successfully. It may take a few days for Google to process it.");
    } else if (status < 400) {
      console.log(`ğŸ•› Indexing already requested previously. It may take a few days for Google to process it.`);
    }
    console.log(``);
  }

  console.log(`ğŸ‘ All done!`);
  console.log(`ğŸ’– Brought to you by https://seogets.com - SEO Analytics.`);
  console.log(``);
};

main();
